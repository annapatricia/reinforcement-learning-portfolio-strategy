
# ğŸ“ˆ RL Portfolio Allocation Agent (PPO)

Projeto end-to-end de Reinforcement Learning para alocaÃ§Ã£o de portfÃ³lio usando dados histÃ³ricos (SPY, QQQ, TLT).
Compara um baseline equal-weight contra um agente PPO treinado para escolher pesos dinamicamente.

---

## ğŸ¯ Objetivo
Treinar um agente de RL (PPO) para decidir pesos de portfÃ³lio e comparar performance com um baseline clÃ¡ssico (1/3 em cada ativo).

---

## ğŸ§  Metodologia (MVP)

Baseline:
Equal-weight (1/3, 1/3, 1/3)

RL Agent (PPO):
- ObservaÃ§Ã£o: janela de retornos passados
- AÃ§Ã£o: pesos do portfÃ³lio (normalizados para somar 1)
- Recompensa: retorno do dia seguinte do portfÃ³lio

---

## ğŸ“Š Resultados (Local MVP)

Sharpe (Baseline): 0.719  
Sharpe (RL): 0.977  

Max Drawdown (Baseline): -30.06%  
Max Drawdown (RL): -28.18%

---

## ğŸ“ˆ Equity Curve (Baseline vs RL)

![Equity Curve](reports/figures/equity_curve_baseline_vs_rl.png)

---

## ğŸ“ Estrutura do repositÃ³rio

```
rl-llm-portfolio-agent/
  README.md
  requirements.txt
  notebooks/
    01_mvp_local.ipynb
  src/
    data.py
    env_portfolio.py
    train_rl.py
    evaluate.py
    plots.py
  reports/
    REPORT.md
    figures/
      normalized_prices.png
      equity_curve_baseline.png
      equity_curve_baseline_vs_rl.png
  docs/
    architecture.mmd
```

---

## â–¶ï¸ Como rodar

Criar ambiente virtual:

python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt

Treinar modelo:

python -m src.train_rl

Avaliar modelo:

python -m src.evaluate

Gerar grÃ¡ficos:

python -m src.plots

---

## ğŸ“Š Out-of-Sample Test Results

Train period: 2020â€“2023  
Test period: 2024â€“2026  

| Metric | Baseline | RL Agent |
|--------|----------|----------|
| Sharpe | 1.03 | 0.927 |
| Max Drawdown | -14.5% | -20.5% |

### ğŸ“ˆ Equity Curve â€” Test Period Only

![Equity Curve Test](reports/figures/equity_curve_test_only.png)


The RL agent underperformed the baseline out-of-sample, suggesting possible overfitting and the need for improved reward design.



