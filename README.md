
# ğŸ“ˆ RL Portfolio Allocation Agent (PPO)

Projeto end-to-end de Reinforcement Learning para alocaÃ§Ã£o de portfÃ³lio usando dados histÃ³ricos (SPY, QQQ, TLT).
Compara um baseline equal-weight contra um agente PPO treinado para escolher pesos dinamicamente.

---

## ğŸ¯ Objetivo
Treinar um agente de RL (PPO) para decidir pesos de portfÃ³lio e comparar performance com um baseline clÃ¡ssico (1/3 em cada ativo).

---

## ğŸ§  Metodologia (MVP)

Baseline:
Equal-weight (1/3, 1/3, 1/3)

RL Agent (PPO):
- ObservaÃ§Ã£o: janela de retornos passados
- AÃ§Ã£o: pesos do portfÃ³lio (normalizados para somar 1)
- Recompensa: retorno do dia seguinte do portfÃ³lio

---

## ğŸ“Š Resultados (Local MVP)

Sharpe (Baseline): 0.719  
Sharpe (RL): 0.977  

Max Drawdown (Baseline): -30.06%  
Max Drawdown (RL): -28.18%

---

## ğŸ“ˆ Equity Curve (Baseline vs RL)

![Equity Curve](reports/figures/equity_curve_baseline_vs_rl.png)

---

## ğŸ“ Repository Structure

```
rl-llm-portfolio-agent/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 01_mvp_local.ipynb        # Initial MVP experimentation
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data.py                  # Data loading and preprocessing
â”‚   â”œâ”€â”€ env_portfolio.py         # Custom RL portfolio environment
â”‚   â”œâ”€â”€ train_rl.py              # Training loop and policy optimization
â”‚   â”œâ”€â”€ evaluate.py              # Performance evaluation metrics
â”‚   â””â”€â”€ plots.py                 # Visualization utilities
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ REPORT.md                # Technical report and results discussion
â”‚   â””â”€â”€ figures/
â”‚       â”œâ”€â”€ normalized_prices.png
â”‚       â”œâ”€â”€ equity_curve_baseline.png
â”‚       â””â”€â”€ equity_curve_baseline_vs_rl.png
â”‚
â””â”€â”€ docs/
    â””â”€â”€ architecture.mmd         # System architecture diagram (Mermaid)
```



---

## â–¶ï¸ Como rodar

Criar ambiente virtual:

python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt

Treinar modelo:

python -m src.train_rl

Avaliar modelo:

python -m src.evaluate

Gerar grÃ¡ficos:

python -m src.plots

---

## ğŸ“Š Out-of-Sample Test Results

Train period: 2020â€“2023  
Test period: 2024â€“2026  

| Metric | Baseline | RL Agent |
|--------|----------|----------|
| Sharpe | 1.03 | 0.927 |
| Max Drawdown | -14.5% | -20.5% |

### ğŸ“ˆ Equity Curve â€” Test Period Only

![Equity Curve Test](reports/figures/equity_curve_test_only.png)


The RL agent underperformed the baseline out-of-sample, suggesting possible overfitting and the need for improved reward design.



